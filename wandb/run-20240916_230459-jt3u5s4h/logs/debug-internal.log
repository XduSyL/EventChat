2024-09-16 23:04:59,862 INFO    StreamThr :1414299 [internal.py:wandb_internal():85] W&B internal server running at pid: 1414299, started at: 2024-09-16 23:04:59.861505
2024-09-16 23:04:59,865 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: status
2024-09-16 23:04:59,867 INFO    WriterThread:1414299 [datastore.py:open_for_write():87] open: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/run-jt3u5s4h.wandb
2024-09-16 23:04:59,871 DEBUG   SenderThread:1414299 [sender.py:send():391] send: header
2024-09-16 23:04:59,871 DEBUG   SenderThread:1414299 [sender.py:send():391] send: run
2024-09-16 23:05:00,667 INFO    SenderThread:1414299 [dir_watcher.py:__init__():211] watching files in: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/files
2024-09-16 23:05:00,668 INFO    SenderThread:1414299 [sender.py:_start_run_threads():1200] run started: jt3u5s4h with start time 1726499099.860264
2024-09-16 23:05:00,681 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: run_start
2024-09-16 23:05:00,706 DEBUG   HandlerThread:1414299 [system_info.py:__init__():26] System info init
2024-09-16 23:05:00,706 DEBUG   HandlerThread:1414299 [system_info.py:__init__():41] System info init done
2024-09-16 23:05:00,706 INFO    HandlerThread:1414299 [system_monitor.py:start():194] Starting system monitor
2024-09-16 23:05:00,707 INFO    SystemMonitor:1414299 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-09-16 23:05:00,707 INFO    HandlerThread:1414299 [system_monitor.py:probe():214] Collecting system info
2024-09-16 23:05:00,707 INFO    SystemMonitor:1414299 [interfaces.py:start():188] Started cpu monitoring
2024-09-16 23:05:00,708 INFO    SystemMonitor:1414299 [interfaces.py:start():188] Started disk monitoring
2024-09-16 23:05:00,708 INFO    SystemMonitor:1414299 [interfaces.py:start():188] Started gpu monitoring
2024-09-16 23:05:00,709 INFO    SystemMonitor:1414299 [interfaces.py:start():188] Started memory monitoring
2024-09-16 23:05:00,710 INFO    SystemMonitor:1414299 [interfaces.py:start():188] Started network monitoring
2024-09-16 23:05:00,756 DEBUG   HandlerThread:1414299 [system_info.py:probe():152] Probing system
2024-09-16 23:05:00,757 DEBUG   HandlerThread:1414299 [gitlib.py:_init_repo():56] git repository is invalid
2024-09-16 23:05:00,757 DEBUG   HandlerThread:1414299 [system_info.py:probe():200] Probing system done
2024-09-16 23:05:00,757 DEBUG   HandlerThread:1414299 [system_monitor.py:probe():223] {'os': 'Linux-5.4.0-195-generic-x86_64-with-glibc2.31', 'python': '3.10.14', 'heartbeatAt': '2024-09-16T15:05:00.757076', 'startedAt': '2024-09-16T15:04:59.856991', 'docker': None, 'cuda': None, 'args': ('--local_rank=0', '--deepspeed', '/data/SyL/LLaVA/scripts/zero2.json', '--model_name_or_path', '/data/SyL/model/vicuna-7b-v1.5', '--version', 'plain', '--data_path', '/data/SyL/LLaVA/data_process/merged_instruction.json', '--image_folder', '/data/SyL/LLaVA/custom_data/images', '--event_folder', '/data/SyL/LLaVA/custom_data/events', '--vision_tower', '/data/SyL/model/clip-vit-large-patch14-336', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', '/data/SyL/LLaVA/checkpoints/llava-v1.5-7b-pretrain', '--num_train_epochs', '4', '--per_device_train_batch_size', '4', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '8', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '100', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb'), 'state': 'running', 'program': '/data/SyL/Event_RGB/deepspeed_train.py', 'codePathLocal': 'deepspeed_train.py', 'codePath': 'deepspeed_train.py', 'host': 'user-X12DPG-OA6', 'username': 'root', 'executable': '/home/user/anaconda3/envs/llava/bin/python', 'cpu_count': 32, 'cpu_count_logical': 64, 'cpu_freq': {'current': 1353.84621875, 'min': 800.0, 'max': 3500.0}, 'cpu_freq_per_core': [{'current': 3306.533, 'min': 800.0, 'max': 3500.0}, {'current': 867.431, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 799.923, 'min': 800.0, 'max': 3500.0}, {'current': 799.853, 'min': 800.0, 'max': 3500.0}, {'current': 799.425, 'min': 800.0, 'max': 3500.0}, {'current': 872.275, 'min': 800.0, 'max': 3500.0}, {'current': 2021.291, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 800.912, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 822.363, 'min': 800.0, 'max': 3500.0}, {'current': 799.421, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 3300.0, 'min': 800.0, 'max': 3500.0}, {'current': 3300.0, 'min': 800.0, 'max': 3500.0}, {'current': 1615.097, 'min': 800.0, 'max': 3500.0}, {'current': 2900.333, 'min': 800.0, 'max': 3500.0}, {'current': 1496.16, 'min': 800.0, 'max': 3500.0}, {'current': 1198.07, 'min': 800.0, 'max': 3500.0}, {'current': 1158.495, 'min': 800.0, 'max': 3500.0}, {'current': 904.7, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 858.438, 'min': 800.0, 'max': 3500.0}, {'current': 809.555, 'min': 800.0, 'max': 3500.0}, {'current': 977.475, 'min': 800.0, 'max': 3500.0}, {'current': 900.0, 'min': 800.0, 'max': 3500.0}, {'current': 803.431, 'min': 800.0, 'max': 3500.0}, {'current': 2900.0, 'min': 800.0, 'max': 3500.0}, {'current': 2518.875, 'min': 800.0, 'max': 3500.0}, {'current': 3303.097, 'min': 800.0, 'max': 3500.0}, {'current': 900.0, 'min': 800.0, 'max': 3500.0}, {'current': 800.354, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 800.709, 'min': 800.0, 'max': 3500.0}, {'current': 881.709, 'min': 800.0, 'max': 3500.0}, {'current': 1016.444, 'min': 800.0, 'max': 3500.0}, {'current': 801.068, 'min': 800.0, 'max': 3500.0}, {'current': 801.156, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 897.011, 'min': 800.0, 'max': 3500.0}, {'current': 800.734, 'min': 800.0, 'max': 3500.0}, {'current': 801.07, 'min': 800.0, 'max': 3500.0}, {'current': 800.352, 'min': 800.0, 'max': 3500.0}, {'current': 3299.698, 'min': 800.0, 'max': 3500.0}, {'current': 3300.0, 'min': 800.0, 'max': 3500.0}, {'current': 2319.118, 'min': 800.0, 'max': 3500.0}, {'current': 2900.363, 'min': 800.0, 'max': 3500.0}, {'current': 1400.321, 'min': 800.0, 'max': 3500.0}, {'current': 1908.698, 'min': 800.0, 'max': 3500.0}, {'current': 818.063, 'min': 800.0, 'max': 3500.0}, {'current': 836.84, 'min': 800.0, 'max': 3500.0}, {'current': 800.0, 'min': 800.0, 'max': 3500.0}, {'current': 829.163, 'min': 800.0, 'max': 3500.0}, {'current': 819.145, 'min': 800.0, 'max': 3500.0}, {'current': 989.449, 'min': 800.0, 'max': 3500.0}, {'current': 900.0, 'min': 800.0, 'max': 3500.0}, {'current': 839.879, 'min': 800.0, 'max': 3500.0}, {'current': 2899.993, 'min': 800.0, 'max': 3500.0}, {'current': 2400.764, 'min': 800.0, 'max': 3500.0}], 'disk': {'/': {'total': 438.05088806152344, 'used': 58.82227325439453}}, 'gpu': 'NVIDIA GeForce RTX 3090', 'gpu_count': 8, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25769803776}], 'memory': {'total': 503.54224014282227}}
2024-09-16 23:05:00,757 INFO    HandlerThread:1414299 [system_monitor.py:probe():224] Finished collecting system info
2024-09-16 23:05:00,757 INFO    HandlerThread:1414299 [system_monitor.py:probe():227] Publishing system info
2024-09-16 23:05:00,757 DEBUG   HandlerThread:1414299 [system_info.py:_save_conda():209] Saving list of conda packages installed into the current environment
2024-09-16 23:05:01,671 INFO    Thread-12 :1414299 [dir_watcher.py:_on_file_created():271] file/dir created: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/files/conda-environment.yaml
2024-09-16 23:05:03,076 DEBUG   HandlerThread:1414299 [system_info.py:_save_conda():224] Saving conda packages done
2024-09-16 23:05:03,076 INFO    HandlerThread:1414299 [system_monitor.py:probe():229] Finished publishing system info
2024-09-16 23:05:03,078 DEBUG   SenderThread:1414299 [sender.py:send():391] send: files
2024-09-16 23:05:03,078 INFO    SenderThread:1414299 [sender.py:_save_file():1466] saving file wandb-metadata.json with policy now
2024-09-16 23:05:03,174 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: python_packages
2024-09-16 23:05:03,175 DEBUG   SenderThread:1414299 [sender.py:send_request():418] send_request: python_packages
2024-09-16 23:05:03,176 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: stop_status
2024-09-16 23:05:03,176 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-16 23:05:03,177 DEBUG   SenderThread:1414299 [sender.py:send():391] send: telemetry
2024-09-16 23:05:03,177 DEBUG   SenderThread:1414299 [sender.py:send_request():418] send_request: stop_status
2024-09-16 23:05:03,668 INFO    Thread-12 :1414299 [dir_watcher.py:_on_file_modified():288] file/dir modified: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/files/conda-environment.yaml
2024-09-16 23:05:03,669 INFO    Thread-12 :1414299 [dir_watcher.py:_on_file_created():271] file/dir created: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/files/wandb-metadata.json
2024-09-16 23:05:03,669 INFO    Thread-12 :1414299 [dir_watcher.py:_on_file_created():271] file/dir created: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/files/requirements.txt
2024-09-16 23:05:03,766 DEBUG   SenderThread:1414299 [sender.py:send():391] send: config
2024-09-16 23:05:03,768 DEBUG   SenderThread:1414299 [sender.py:send():391] send: telemetry
2024-09-16 23:05:03,768 DEBUG   SenderThread:1414299 [sender.py:send():391] send: metric
2024-09-16 23:05:03,768 DEBUG   SenderThread:1414299 [sender.py:send():391] send: telemetry
2024-09-16 23:05:03,768 DEBUG   SenderThread:1414299 [sender.py:send():391] send: metric
2024-09-16 23:05:03,768 WARNING SenderThread:1414299 [sender.py:send_metric():1417] Seen metric with glob (shouldn't happen)
2024-09-16 23:05:03,768 DEBUG   SenderThread:1414299 [sender.py:send():391] send: telemetry
2024-09-16 23:05:04,248 INFO    wandb-upload_0:1414299 [upload_job.py:push():130] Uploaded file /tmp/tmp3cuoebymwandb/wxvr6ewa-wandb-metadata.json
2024-09-16 23:05:04,669 INFO    Thread-12 :1414299 [dir_watcher.py:_on_file_created():271] file/dir created: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/files/output.log
2024-09-16 23:05:05,769 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: status_report
2024-09-16 23:05:06,670 INFO    Thread-12 :1414299 [dir_watcher.py:_on_file_modified():288] file/dir modified: /data/SyL/Event_RGB/wandb/run-20240916_230459-jt3u5s4h/files/output.log
2024-09-16 23:05:11,176 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: status_report
2024-09-16 23:05:13,176 DEBUG   HandlerThread:1414299 [handler.py:handle_request():158] handle_request: internal_messages
